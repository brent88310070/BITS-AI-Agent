import os
import sys
import json
import psutil
import GPUtil
import pynvml
from datetime import datetime
from langchain_core.tools import tool, StructuredTool
import asyncio
from contextlib import AsyncExitStack

# === MCP Imports ===
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

STORAGE_DIR = os.path.abspath("data_storage").replace("\\", "/")
if not os.path.exists(STORAGE_DIR):
    os.makedirs(STORAGE_DIR)

# ============================================================
# ğŸ§© æœ¬åœ°å·¥å…·å®šç¾© (ä¿æŒä¸è®Š)
# ============================================================

@tool("system_info")
def system_info() -> str:
    """CPU and RAM usage"""
    mem = psutil.virtual_memory()
    return (f"ğŸ–¥ï¸ CPU: {psutil.cpu_count()} cores, Usage: {psutil.cpu_percent()}%\n"
            f"ğŸ’¾ RAM: {mem.used / 1e9:.2f}/{mem.total / 1e9:.2f} GB")

@tool("get_time")
def get_time() -> str:
    """Current time"""
    time = datetime.now().strftime("ğŸ•‘ %Y-%m-%d (%A) %H:%M:%S")
    print(time)
    return time

@tool("gpu_info")
def gpu_info() -> str:
    """Get NVIDIA GPU status (Load, Memory, Temperature)"""
    try:
        gpus = GPUtil.getGPUs()
        if not gpus:
            return "âŒ No NVIDIA GPU detected."
        
        info = []
        for gpu in gpus:
            used_gb = gpu.memoryUsed / 1024
            total_gb = gpu.memoryTotal / 1024
            gpu_status = (f"ğŸ® GPU: {gpu.name} | Load: {gpu.load*100:.1f}% | "
                          f"Temp: {gpu.temperature}Â°C | "
                          f"Mem: {used_gb:.2f}/{total_gb:.2f} GB")
            info.append(gpu_status)
        return "\n".join(info)
    except Exception as e:
        return f"âš ï¸ Could not retrieve GPU info: {str(e)}"

@tool("disk_info")
def disk_info() -> str:
    """Get Disk/Storage usage for the root directory"""
    usage = psutil.disk_usage('/')
    return (f"ğŸ’½ Disk: {usage.used / 1e9:.2f}/{usage.total / 1e9:.2f} GB "
            f"({usage.percent}% used)")

@tool("resource_monitor")
def resource_monitor() -> str:
    """Identify top CPU, RAM, and GPU consuming processes and their scripts."""
    processes = []
    
    # 1. å–å¾— CPU èˆ‡ RAM çš„è¡Œç¨‹è³‡è¨Š
    for proc in psutil.process_iter(['pid', 'name', 'username', 'cpu_percent', 'memory_info', 'cmdline']):
        try:
            info = proc.info
            cmdline = " ".join(info['cmdline']) if info['cmdline'] else ""
            is_script = any(ext in cmdline.lower() for ext in ['.py', '.sh', '.r', '.pl', '.ipynb', 'python', 'node'])
            
            processes.append({
                'pid': info['pid'],
                'user': info['username'],
                'name': info['name'],
                'cpu': info['cpu_percent'],
                'mem': info['memory_info'].rss / 1e9,
                'script': cmdline if is_script else None,
                'gpu_mem': 0,
                'gpu_id': None
            })
        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
            pass

    # 2. å–å¾— GPU è¡Œç¨‹è³‡è¨Š (ä½¿ç”¨ NVML)
    gpu_processes = []
    try:
        pynvml.nvmlInit()
        device_count = pynvml.nvmlDeviceGetCount()
        for i in range(device_count):
            handle = pynvml.nvmlDeviceGetHandleByIndex(i)
            procs = pynvml.nvmlDeviceGetComputeRunningProcesses(handle)
            for p in procs:
                gpu_processes.append({
                    'pid': p.pid,
                    'gpu_id': i,
                    'gpu_mem': p.usedGpuMemory / 1e9 
                })
        pynvml.nvmlShutdown()
    except Exception:
        pass 

    # 3. å°‡ GPU æ•¸æ“šåˆä½µå›ä¸»åˆ—è¡¨
    for gp in gpu_processes:
        for p in processes:
            if p['pid'] == gp['pid']:
                p['gpu_mem'] = gp['gpu_mem']
                p['gpu_id'] = gp['gpu_id']

    # 4. æ’åºä¸¦ç”¢å‡ºçµæœ
    top_cpu = sorted(processes, key=lambda x: x['cpu'], reverse=True)[:3]
    top_mem = sorted(processes, key=lambda x: x['mem'], reverse=True)[:3]
    top_gpu = sorted([p for p in processes if p['gpu_mem'] > 0], key=lambda x: x['gpu_mem'], reverse=True)[:3]

    result = ["ğŸ“Š **Resource Consumption Leaderboard**"]
    
    result.append("\nğŸ”¥ Top 3 CPU Usage:")
    for p in top_cpu:
        s = f" (ğŸ“œ {p['script'][:40]}...)" if p['script'] else ""
        result.append(f"- User: {p['user']} | CPU: {p['cpu']}% | Proc: {p['name']}{s}")

    result.append("\nğŸ§  Top 3 RAM Usage:")
    for p in top_mem:
        s = f" (ğŸ“œ {p['script'][:40]}...)" if p['script'] else ""
        result.append(f"- User: {p['user']} | Mem: {p['mem']:.2f} GB | Proc: {p['name']}{s}")

    if top_gpu:
        result.append("\nğŸ® Top 3 GPU Usage:")
        for p in top_gpu:
            s = f" (ğŸ“œ {p['script'][:40]}...)" if p['script'] else ""
            result.append(f"- User: {p['user']} | GPU[{p['gpu_id']}] VRAM: {p['gpu_mem']:.2f} GB | Proc: {p['name']}{s}")
    else:
        result.append("\nğŸ® GPU Usage: No active GPU compute processes found.")

    return "\n".join(result)

@tool("list_storage_files")
def list_storage_files() -> str:
    """
    List filenames in the data_storage directory.
    IMPORTANT RESTRICTION:
    - Use this tool ONLY when the user asks "what files are there?" or "show the file list".
    - If the user specifies a filename (e.g., "read test.csv", "get column from data.csv"), DO NOT USE THIS TOOL.
    - Instead, use the SQL tool directly to query the file.
    """
    if not os.path.exists(STORAGE_DIR): return "ğŸ“‚ Directory empty."
    files = os.listdir(STORAGE_DIR)
    info = []
    for f in files:
        path = os.path.join(STORAGE_DIR, f)
        size = os.path.getsize(path) / (1024*1024)
        info.append(f"- {f} ({size:.4f} MB)")
    return f"ğŸ“‚ **Files in {STORAGE_DIR}:**\n" + "\n".join(info)

# ============================================================
# ğŸŒ‰ Tool Loader
# ============================================================
_mcp_exit_stack = AsyncExitStack()

async def connect_to_mcp_server(command: str, args: list[str], env: dict = None):
    """é€£ç·šåˆ°æŒ‡å®šçš„ MCP Server ä¸¦å›å‚³ tools"""
    server_params = StdioServerParameters(
        command=command,
        args=args,
        env=env
    )
    
    try:
        read_stream, write_stream = await _mcp_exit_stack.enter_async_context(stdio_client(server_params))
        session = await _mcp_exit_stack.enter_async_context(ClientSession(read_stream, write_stream))
        await session.initialize()
        
        mcp_list_tools = await session.list_tools()
        langchain_tools = []

        for mcp_tool in mcp_list_tools.tools:
            # === ğŸ’¡ FIX 1: å‹•æ…‹æ³¨å…¥è·¯å¾‘æŒ‡å¼• ===
            # æˆ‘å€‘ä¿®æ”¹å·¥å…·æè¿°ï¼Œå¼·åˆ¶ LLM çŸ¥é“æª”æ¡ˆéƒ½åœ¨ data_storage è³‡æ–™å¤¾ä¸‹
            # ä¸¦è¦æ±‚å®ƒåœ¨ SQL æŸ¥è©¢æ™‚ä½¿ç”¨çµ•å°è·¯å¾‘æˆ–æ­£ç¢ºçš„ç›¸å°è·¯å¾‘
            enhanced_description = mcp_tool.description
            if "sql" in mcp_tool.name.lower() or "query" in mcp_tool.name.lower():
                enhanced_description += (
                    f"\n\n IMPORTANT PATH INSTRUCTION \n"
                    f"All CSV/Parquet files are located in: '{STORAGE_DIR}'\n"
                    f"When writing SQL, you MUST prepend the path to the filename.\n"
                    f"Example: SELECT * FROM read_csv('{STORAGE_DIR}/your_file.csv');"
                )

            # ä½¿ç”¨é–‰åŒ…æ•ç²ç•¶å‰ tool çš„è³‡è¨Š
            def make_wrapper(tool_name, tool_session):
                async def _tool_wrapper(**kwargs):
                    try:
                        if "kwargs" in kwargs and isinstance(kwargs["kwargs"], dict):
                            actual_args = kwargs["kwargs"]
                        else:
                            actual_args = kwargs
                        
                        # === [DEBUG] 1. å°å‡ºé€å‡ºçš„æŒ‡ä»¤ ===
                        print(f"\nğŸ“ [MCP DEBUG] Sending to {tool_name}:")
                        if "query" in actual_args:
                            print(f"   ğŸ‘‰ SQL: {actual_args['query']}")
                        else:
                            print(f"   ğŸ‘‰ Args: {json.dumps(actual_args, ensure_ascii=False)}")
                        print("-" * 50)
                        
                        # åŸ·è¡Œå·¥å…·
                        result = await tool_session.call_tool(tool_name, arguments=actual_args)
                        
                        # === [DEBUG] 2. å°å‡ºæ”¶åˆ°çš„çµæœ (ğŸ’¡ æ–°å¢é€™è£¡) ===
                        print(f"ğŸ“¥ [MCP DEBUG] Received from {tool_name}:")
                        if result.content:
                            for content in result.content:
                                if content.type == "text":
                                    # é¿å…çµæœå¤ªé•·æ´—ç‰ˆï¼Œè¶…é 500 å­—å…ƒå°±æˆªæ–·é¡¯ç¤º
                                    display_text = content.text
                                    if len(display_text) > 500:
                                        display_text = display_text[:500] + "\n... [truncated] ..."
                                    print(f"   ğŸ“„ Data:\n{display_text}")
                                else:
                                    print(f"   ğŸ“¦ Object ({content.type}): {content}")
                        else:
                            print("   âš ï¸ No content returned (Empty).")
                        print("=" * 50 + "\n")
                        # ==============================================
                        
                        output_text = []
                        if result.content:
                            for content in result.content:
                                if content.type == "text":
                                    output_text.append(content.text)
                        
                        # === ğŸ’¡ FIX 2: éŒ¯èª¤æ””æˆªèˆ‡æç¤º (é‡å°å•é¡Œ2çš„è¼”åŠ©) ===
                        final_output = "\n".join(output_text) if output_text else "No output."
                        
                        # å¦‚æœ DuckDB å›å‚³æ‰¾ä¸åˆ°æª”æ¡ˆçš„éŒ¯èª¤ï¼Œæˆ‘å€‘åœ¨å·¥å…·è¼¸å‡ºä¸­å·å·åŠ ä¸€å¥æç¤º
                        # é€™æœƒåˆºæ¿€ LLM è‡ªå‹•ä¿®æ­£ï¼Œè€Œä¸æ˜¯åªæœ‰å ±éŒ¯
                        if "No such file or directory" in final_output:
                            final_output += f"\n\nâš ï¸ SYSTEM HINT: The file was not found. Did you forget to add the path '{STORAGE_DIR}/'?"

                        if "validation error" in final_output.lower() or "required property" in final_output.lower():
                            final_output += (
                                f"\n\nâš ï¸ SYSTEM HINT: Argument Error. "
                                f"You MUST use the 'query' argument with a valid SQL string.\n"
                                f"Do NOT pass 'file' or 'head' directly.\n"
                                f"Correct Example: {{'query': \"SELECT * FROM read_csv('{STORAGE_DIR}/filename.csv') LIMIT 5\"}}"
                            )
                            
                        return final_output

                    except Exception as tool_err:
                        return f"âŒ Tool execution failed: {tool_err}"
                return _tool_wrapper

            lc_tool = StructuredTool.from_function(
                func=None,
                coroutine=make_wrapper(mcp_tool.name, session),
                name=mcp_tool.name,
                description=enhanced_description, # ä½¿ç”¨ä¿®æ”¹å¾Œçš„æè¿°
            )
            langchain_tools.append(lc_tool)
            print(f"ğŸ”— Loaded MCP Tool: {mcp_tool.name} (with path injection)")
            
        return langchain_tools

    except Exception as e:
        print(f"âŒ Failed to connect to MCP server ({command}): {e}")
        import traceback
        traceback.print_exc()
        return []

async def get_all_tools_async():
    """éåŒæ­¥:è¼‰å…¥æœ¬åœ°å·¥å…·èˆ‡ DuckDB MCP å·¥å…·"""
    
    # 1. åŸºæœ¬æœ¬åœ°å·¥å…·
    tools = [system_info, get_time, gpu_info, disk_info, resource_monitor, list_storage_files]
    
    # 2. MCP Server: DuckDB (MotherDuck å®˜æ–¹ç‰ˆæœ¬)
    print("â³ Connecting to MCP: DuckDB (MotherDuck official server)...")
    print(f"ğŸ“‚ Working Directory: {STORAGE_DIR}")
    
    # å»ºç«‹ä¸€å€‹æœ¬åœ° DuckDB è³‡æ–™åº«è·¯å¾‘
    mcp_env = os.environ.copy()
    mcp_env["CSV_DIR"] = STORAGE_DIR  # è¨­å®š CSV ç›®éŒ„ç’°å¢ƒè®Šæ•¸
    
    # MotherDuck çš„ DuckDB MCP Server
    # åŠŸèƒ½:
    # - åŸ·è¡Œ SQL æŸ¥è©¢åˆ†æ CSV/Parquet/JSON
    # - ä½¿ç”¨ DuckDB çš„ read_csv() å‡½æ•¸ç›´æ¥è®€å–æª”æ¡ˆ
    # - æ”¯æ´è¤‡é›œçš„ SQL åˆ†æ (JOIN, GROUP BY, èšåˆå‡½æ•¸ç­‰)
    # - å¯æŸ¥è©¢æœ¬åœ°æª”æ¡ˆæˆ– S3 é ç«¯è³‡æ–™
    mcp_tools = await connect_to_mcp_server(
        command="uvx",
        args=[
            "mcp-server-motherduck",  # MotherDuck å®˜æ–¹ DuckDB MCP Server
            "--db-path", ":memory:",  # ä½¿ç”¨è¨˜æ†¶é«”æ¨¡å¼ï¼Œä¸å»ºç«‹å¯¦é«”æª”æ¡ˆ
        ],
        env=mcp_env
    )
    
    tools.extend(mcp_tools)
    
    print(f"âœ… Total tools loaded: {len(tools)}")
    print(f"ğŸ’¡ Tip: You can query CSV files using SQL like:")
    print(f"   SELECT * FROM read_csv('{STORAGE_DIR}/your_file.csv') LIMIT 10;")
    
    return tools